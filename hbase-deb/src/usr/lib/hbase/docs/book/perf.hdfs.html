<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   <title>12.11.&nbsp;HDFS</title><link rel="stylesheet" type="text/css" href="../css/freebsd_docbook.css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.76.1"><link rel="home" href="book.html" title="The Apache HBase&#153; Reference Guide"><link rel="up" href="performance.html" title="Chapter&nbsp;12.&nbsp;Apache HBase Performance Tuning"><link rel="prev" href="perf.deleting.html" title="12.10.&nbsp;Deleting from HBase"><link rel="next" href="perf.ec2.html" title="12.12.&nbsp;Amazon EC2"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">12.11.&nbsp;HDFS</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="perf.deleting.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;12.&nbsp;Apache HBase Performance Tuning</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="perf.ec2.html">Next</a></td></tr></table><hr></div><div class="section" title="12.11.&nbsp;HDFS"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="perf.hdfs"></a>12.11.&nbsp;HDFS</h2></div></div></div><p>Because HBase runs on <a class="xref" href="arch.hdfs.html" title="9.9.&nbsp;HDFS">Section&nbsp;9.9, &#8220;HDFS&#8221;</a> it is important to understand how it works and how it affects
   HBase.
   </p><div class="section" title="12.11.1.&nbsp;Current Issues With Low-Latency Reads"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hdfs.curr"></a>12.11.1.&nbsp;Current Issues With Low-Latency Reads</h3></div></div></div><p>The original use-case for HDFS was batch processing.  As such, there low-latency reads were historically not a priority.
      With the increased adoption of Apache HBase this is changing, and several improvements are already in development.
      See the
      <a class="link" href="https://issues.apache.org/jira/browse/HDFS-1599" target="_top">Umbrella Jira Ticket for HDFS Improvements for HBase</a>.
      </p></div><div class="section" title="12.11.2.&nbsp;Leveraging local data"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hdfs.configs.localread"></a>12.11.2.&nbsp;Leveraging local data</h3></div></div></div><p>Since Hadoop 1.0.0 (also 0.22.1, 0.23.1, CDH3u3 and HDP 1.0) via
<a class="link" href="https://issues.apache.org/jira/browse/HDFS-2246" target="_top">HDFS-2246</a>,
it is possible for the DFSClient to take a "short circuit" and
read directly from disk instead of going through the DataNode when the
data is local. What this means for HBase is that the RegionServers can
read directly off their machine's disks instead of having to open a
socket to talk to the DataNode, the former being generally much
faster<sup>[<a name="d366e9408" href="#ftn.d366e9408" class="footnote">31</a>]</sup>.
Also see <a class="link" href="http://search-hadoop.com/m/zV6dKrLCVh1" target="_top">HBase, mail # dev - read short circuit</a> thread for
more discussion around short circuit reads.
</p><p>To enable "short circuit" reads, it will depend on your version of Hadoop.
    The original shortcircuit read patch was much improved upon in Hadoop 2 in
    <a class="link" href="https://issues.apache.org/jira/browse/HDFS-347" target="_top">HDFS-347</a>.
    See <a class="link" href="http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/" target="_top">http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/</a> for details
    on the difference between the old and new implementations.  See
    <a class="link" href="http://archive.cloudera.com/cdh4/cdh/4/hadoop/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html" target="_top">Hadoop shortcircuit reads configuration page</a>
    for how to enable the later version of shortcircuit.
</p><p>If you are running on an old Hadoop, one that is without
    <a class="link" href="https://issues.apache.org/jira/browse/HDFS-347" target="_top">HDFS-347</a> but that
    has
<a class="link" href="https://issues.apache.org/jira/browse/HDFS-2246" target="_top">HDFS-2246</a>,
you must set two configurations.
First, the hdfs-site.xml needs to be amended. Set
the property  <code class="varname">dfs.block.local-path-access.user</code>
to be the <span class="emphasis"><em>only</em></span> user that can use the shortcut.
This has to be the user that started HBase.  Then in hbase-site.xml,
set <code class="varname">dfs.client.read.shortcircuit</code> to be <code class="varname">true</code>
</p><p>
    For optimal performance when short-circuit reads are enabled, it is recommended that HDFS checksums are disabled.
    To maintain data integrity with HDFS checksums disabled, HBase can be configured to write its own checksums into
    its datablocks and verify against these. See <a class="xref" href="config.files.html#hbase.regionserver.checksum.verify" title="hbase.regionserver.checksum.verify"><code class="varname">hbase.regionserver.checksum.verify</code></a>. When both
    local short-circuit reads and hbase level checksums are enabled, you SHOULD NOT disable configuration parameter
    "dfs.client.read.shortcircuit.skip.checksum", which will cause skipping checksum on non-hfile reads. HBase already
    manages that setting under the covers.
</p><p>
The DataNodes need to be restarted in order to pick up the new
configuration. Be aware that if a process started under another
username than the one configured here also has the shortcircuit
enabled, it will get an Exception regarding an unauthorized access but
the data will still be read.
</p><div class="note" title="dfs.client.read.shortcircuit.buffer.size" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a name="dfs.client.read.shortcircuit.buffer.size"></a>dfs.client.read.shortcircuit.buffer.size</h3><p>The default for this value is too high when running on a highly trafficed HBase.  Set it down from its
        1M default down to 128k or so.  Put this configuration in the HBase configs (its a HDFS client-side configuration).
        The Hadoop DFSClient in HBase will allocate a direct byte buffer of this size for <span class="emphasis"><em>each</em></span>
    block it has open; given HBase keeps its HDFS files open all the time, this can add up quickly.</p></div></div><div class="section" title="12.11.3.&nbsp;Performance Comparisons of HBase vs. HDFS"><div class="titlepage"><div><div><h3 class="title"><a name="perf.hdfs.comp"></a>12.11.3.&nbsp;Performance Comparisons of HBase vs. HDFS</h3></div></div></div><p>A fairly common question on the dist-list is why HBase isn't as performant as HDFS files in a batch context (e.g., as
     a MapReduce source or sink).  The short answer is that HBase is doing a lot more than HDFS (e.g., reading the KeyValues,
     returning the most current row or specified timestamps, etc.), and as such HBase is 4-5 times slower than HDFS in this
     processing context.  There is room for improvement and this gap will, over time, be reduced, but HDFS
      will always be faster in this use-case.
     </p></div><div class="footnotes"><br><hr width="100" align="left"><div class="footnote"><p><sup>[<a id="ftn.d366e9408" href="#d366e9408" class="para">31</a>] </sup>See JD's <a class="link" href="http://files.meetup.com/1350427/hug_ebay_jdcryans.pdf" target="_top">Performance Talk</a></p></div></div></div><div id="disqus_thread"></div><script type="text/javascript">
    var disqus_shortname = 'hbase'; // required: replace example with your forum shortname
    var disqus_url = 'http://hbase.apache.org/book';
    var disqus_identifier = 'perf.hdfs';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="perf.deleting.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="performance.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="perf.ec2.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">12.10.&nbsp;Deleting from HBase&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="book.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;12.12.&nbsp;Amazon EC2</td></tr></table></div></body></html>